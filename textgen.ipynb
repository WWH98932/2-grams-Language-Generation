{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: split thr txt file into tokens\n",
    "def next_7words(inputfile, inputword):\n",
    "    with open(inputfile, 'r') as f:    \n",
    "        words = f.read().lower().replace('.', '').replace(',', '').replace('?', '').replace('!', '').replace(';', '').split()\n",
    "    \n",
    "# Step 2: compute sorted list of words in the given file\n",
    "    wordlist = []\n",
    "    for word in words:\n",
    "        if word not in wordlist:\n",
    "            wordlist.append(word)\n",
    "\n",
    "# Step 3: creat 2-grams frequency matrix\n",
    "    bigrams_matrix = np.zeros([len(wordlist), len(wordlist)])\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams_matrix[wordlist.index(words[i])][wordlist.index(words[i + 1])] += 1\n",
    "\n",
    "# Step 4: find the max-likelyhood next word\n",
    "    def nextword(inputword):\n",
    "        if inputword in wordlist:\n",
    "            row = list(bigrams_matrix[wordlist.index(inputword)])\n",
    "            max_column = max(row)\n",
    "            position = row.index(max_column)\n",
    "            return wordlist[position]\n",
    "        else:\n",
    "            return \"Your word is not in the text file\"\n",
    "    \n",
    "# Step 5: creat a seven-word-length sentence\n",
    "    word_0 = inputword\n",
    "    word_1 = nextword(word_0)\n",
    "    word_2 = nextword(word_1)\n",
    "    word_3 = nextword(word_2)\n",
    "    word_4 = nextword(word_3)\n",
    "    word_5 = nextword(word_4)\n",
    "    word_6 = nextword(word_5)\n",
    "    if \"Your word is not in the text file\" not in nextword(inputword):\n",
    "        print(word_0 + \" \" + word_1 + \" \" + word_2 + \" \" + word_3 + \" \" + word_4 + \" \" + word_5 + \" \" + word_6)\n",
    "    else:\n",
    "        print(\"Your word is not in the text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your word is not in the text file\n"
     ]
    }
   ],
   "source": [
    "next_7words(\"LSA_2018.txt\", \"vedio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential problems:\n",
    "1. For example we have to sentences: \"I like Data Science.\" and \"Iqbal is my professor.\" When we split them by \".\" period, the word \"science\" will followed by \"Iqbal\", however, they are not in the same sentence so they should not be considered as sequent words.\n",
    "2. 2-grams has a obvious drawback, for example, the term \"more and more\", they appeared several times in the file and as long we get one \"and\", it will enter a loop like \"more and more and more and more...\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
